{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2023 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Harm Taxonomy\n",
    "\n",
    "In this notebook, we convert the harm taxonomy into a structured JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import google.generativeai as palm\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from json import load, dump\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "\n",
    "api_key = input('PaLM api key:')\n",
    "palm.configure(api_key=api_key)\n",
    "\n",
    "SEED = 51923"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "failure_modes = {\n",
    "    \"unsafe\": {\n",
    "        \"name\": \"Unsafe Content\",\n",
    "        \"description\": \"Generate child sexual abuse and exploitation content, sexually explicit content, or realistic violence and gore.\",\n",
    "    },\n",
    "    \"toxic\": {\n",
    "        \"name\": \"Toxic Content\",\n",
    "        \"description\": \"Generate discriminatory, malicious, abusive content, or harsh profanity.\",\n",
    "    },\n",
    "    \"inaccurate\": {\n",
    "        \"name\": \"Inaccurate Content\",\n",
    "        \"description\": \"Generate inaccurate information; provide legal, financial, or health advice.\",\n",
    "    },\n",
    "    \"opinionated\": {\n",
    "        \"name\": \"Opinionated Content\",\n",
    "        \"description\": \"Express opinions on sensitive topics; endorse brands; generate conspiratorial content.\",\n",
    "    },\n",
    "    \"privacy\": {\n",
    "        \"name\": \"Privacy\",\n",
    "        \"description\": \"Reveal individual's information and data; provenance.\",\n",
    "    },\n",
    "    'illegal': {\n",
    "        'name': 'Harmful Activities',\n",
    "        'description': 'Promote or enable illegal, malicious, or harmful activities.'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "representational_harm = {\n",
    "    \"name\": \"Representational harms\",\n",
    "    \"description\": \"When algorithmic systems reinforce the subordination of social groups along the lines of identity\",\n",
    "    \"harms\": [],\n",
    "}\n",
    "\n",
    "representational_harm[\"harms\"].append(\n",
    "    {\n",
    "        \"name\": \"Stereotyping\",\n",
    "        \"description\": \"Oversimplified and undesirable representations\",\n",
    "        'failureModes': ['unsafe', 'toxic', 'opinionated']\n",
    "    }\n",
    ")\n",
    "\n",
    "representational_harm[\"harms\"].append(\n",
    "    {\n",
    "        \"name\": \"Demeaning and alienating social groups\",\n",
    "        \"description\": \"Narratives used to socially control or oppress social groups\",\n",
    "        'failureModes': ['unsafe', 'toxic', 'opinionated']\n",
    "    }\n",
    ")\n",
    "\n",
    "representational_harm[\"harms\"].append(\n",
    "    {\n",
    "        \"name\": \"Denying people opportunity to self-identify\",\n",
    "        \"description\": \"Non-consensual classifications or representations of a person in algorithmic systems\",\n",
    "        'failureModes': ['unsafe', 'toxic', 'opinionated']\n",
    "    }\n",
    ")\n",
    "\n",
    "# representational_harm[\"harms\"].append(\n",
    "#     {\n",
    "#         \"name\": \"Demeaning social groups\",\n",
    "#         \"description\": \"Narratives used to socially control or oppress social groups\",\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# representational_harm[\"harms\"].append(\n",
    "#     {\n",
    "#         \"name\": \"Erasing social groups\",\n",
    "#         \"description\": \"Unequal visibility of certain social groups\",\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# representational_harm[\"harms\"].append(\n",
    "#     {\n",
    "#         \"name\": \"Alienating social group\",\n",
    "#         \"description\": \"Failure to acknowledge one's membership in a culturally significant social group\",\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# representational_harm[\"harms\"].append(\n",
    "#     {\n",
    "#         \"name\": \"Denying people opportunity to self-identify\",\n",
    "#         \"description\": \"Non-consensual classifications or representations of a person in algorithmic systems\",\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# representational_harm[\"harms\"].append(\n",
    "#     {\n",
    "#         \"name\": \"Reifying essentialist social categories\",\n",
    "#         \"description\": 'Reinforcing socially constructed categories as \"natural\"',\n",
    "#     }\n",
    "# )\n",
    "\n",
    "allocative_harms = {\n",
    "    \"name\": \"Allocative harms\",\n",
    "    \"description\": \"When algorithmic systems withholds opportunities, resources, or information in domains that affect material well-being (e.g., finance, education, employment, healthcare, housing, insurance, and social welfare)\",\n",
    "    \"harms\": [],\n",
    "}\n",
    "\n",
    "allocative_harms[\"harms\"].append(\n",
    "    {\n",
    "        \"name\": \"Opportunity loss\",\n",
    "        \"description\": \"Inequitable access to information, services, or resources needed to equitably participate in society\",\n",
    "        'failureModes': ['inaccurate', 'opinionated']\n",
    "    }\n",
    ")\n",
    "\n",
    "allocative_harms[\"harms\"].append(\n",
    "    {\n",
    "        \"name\": \"Economic loss\",\n",
    "        \"description\": \"Financial losses, employment discrimination\",\n",
    "        'failureModes': ['inaccurate', 'opinionated']\n",
    "    }\n",
    ")\n",
    "\n",
    "quality_harms = {\n",
    "    \"name\": \"Quality of service harms\",\n",
    "    \"description\": \"When algorithmic systems disproportionately fail for certain groups of people along the lines of identity (e.g., gender, race and ethnicity, disability)\",\n",
    "    \"harms\": [],\n",
    "}\n",
    "\n",
    "quality_harms[\"harms\"].append(\n",
    "    {\n",
    "        \"name\": \"Alienation\",\n",
    "        \"description\": \"Feelings of frustration and exclusion when interacting with technologies that fail based on oneâ€™s identity.\",\n",
    "        'failureModes': ['unsafe', 'toxic', 'opinionated']\n",
    "    }\n",
    ")\n",
    "\n",
    "quality_harms[\"harms\"].append(\n",
    "    {\n",
    "        \"name\": \"Increased labor\",\n",
    "        \"description\": \"Additional effort required to make technologies operate, wasted time/labor based on technology failures\",\n",
    "        'failureModes': ['inaccurate', 'illegal']\n",
    "    }\n",
    ")\n",
    "\n",
    "quality_harms[\"harms\"].append(\n",
    "    {\n",
    "        \"name\": \"Service or benefit loss\",\n",
    "        \"description\": \"Disproportionate loss of technological benefits\",\n",
    "        'failureModes': ['inaccurate', 'opinionated']\n",
    "    }\n",
    ")\n",
    "\n",
    "interpersonal_harms = {\n",
    "    \"name\": \"Interpersonal harms\",\n",
    "    \"description\": \"When technological affordances adversely shape relations between people and communities\",\n",
    "    \"harms\": []\n",
    "}\n",
    "\n",
    "interpersonal_harms[\"harms\"].append(\n",
    "    {\n",
    "        \"name\": \"Loss of agency or social control\",\n",
    "        \"description\": \"Loss of autonomy, required use of specific technologies to access domains that affect material well-being\",\n",
    "        'failureModes': ['inaccurate', 'opinionated', 'privacy']\n",
    "    }\n",
    ")\n",
    "\n",
    "interpersonal_harms[\"harms\"].append(\n",
    "    {\n",
    "        \"name\": \"Technology-facilitated violence\",\n",
    "        \"description\": \"Inciting or enabling offline violence, online abuse\",\n",
    "        'failureModes': ['illegal']\n",
    "    }\n",
    ")\n",
    "\n",
    "interpersonal_harms[\"harms\"].append(\n",
    "    {\n",
    "        \"name\": \"Diminished health and well-being\",\n",
    "        \"description\": \"Emotional harms, physical harms, reputational harms\",\n",
    "        'failureModes': ['inaccurate', 'opinionated', 'illegal']\n",
    "    }\n",
    ")\n",
    "\n",
    "interpersonal_harms[\"harms\"].append(\n",
    "    {\n",
    "        \"name\": \"Privacy violations\",\n",
    "        \"description\": \"Non-consensual data collection, identity theft, doxxing, plagiarism\",\n",
    "        'failureModes': ['privacy', 'illegal']\n",
    "    }\n",
    ")\n",
    "\n",
    "societal_harms = {\n",
    "    \"name\": \"Societal harms\",\n",
    "    \"description\": \"The adverse macro-level societal effects of algorithmic systems (e.g., systematizing inequality, accelerating the scale of harm)\",\n",
    "    \"harms\": []\n",
    "}\n",
    "\n",
    "societal_harms[\"harms\"].append(\n",
    "    {\n",
    "        \"name\": \"Information harms\",\n",
    "        \"description\": \"Disinformation, misinformation, malinformation, distortion of reality\",\n",
    "        'failureModes': ['inaccurate']\n",
    "    }\n",
    ")\n",
    "\n",
    "societal_harms[\"harms\"].append(\n",
    "    {\n",
    "        \"name\": \"Cultural harms\",\n",
    "        \"description\": \"Cultural hegemony, proliferating false perceptions about cultural groups\",\n",
    "        'failureModes': ['inaccurate', 'opinionated']\n",
    "    }\n",
    ")\n",
    "\n",
    "societal_harms[\"harms\"].append(\n",
    "    {\n",
    "        \"name\": \"Political and civic harms\",\n",
    "        \"description\": \"Erosion of democracy, legal system harms, nation destabilization\",\n",
    "        'failureModes': ['inaccurate', 'opinionated', 'illegal']\n",
    "    }\n",
    ")\n",
    "\n",
    "societal_harms[\"harms\"].append(\n",
    "    {\n",
    "        \"name\": \"Macro socio-economic harms\",\n",
    "        \"description\": \"loss of jobs, labor exploitation\",\n",
    "        'failureModes': ['inaccurate', 'opinionated', 'illegal']\n",
    "    }\n",
    ")\n",
    "\n",
    "societal_harms[\"harms\"].append(\n",
    "    {\n",
    "        \"name\": \"Environmental harms\",\n",
    "        \"description\": \"Damage to natural environment, animals, and property\",\n",
    "        'failureModes': ['illegal']\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "harm_taxonomy = {\n",
    "    \"Representational harms\": representational_harm,\n",
    "    \"Allocative harms\": allocative_harms,\n",
    "    \"Quality of service harms\": quality_harms,\n",
    "    \"Interpersonal harms\": interpersonal_harms,\n",
    "    \"Societal harms\": societal_harms,\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Link Harms to Accident Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2950, 768)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = load(open('./accident-report-embeddings.json', 'r'))\n",
    "accident_reports = load(open('./report_documents.json', 'r'))\n",
    "doc_embeddings = np.array(embeddings['embeddings'])\n",
    "doc_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_palm_embedding(text):\n",
    "    model = \"models/embedding-gecko-001\"\n",
    "    # Note: PaLM embedding is cased\n",
    "    embedding = palm.generate_embeddings(model=model, text=text)\n",
    "    return embedding['embedding']\n",
    "\n",
    "for k in harm_taxonomy:\n",
    "    cur_theme = harm_taxonomy[k]\n",
    "    for harm in cur_theme[\"harms\"]:\n",
    "        cur_context = (\n",
    "            harm[\"name\"]\n",
    "            + \" : \"\n",
    "            + harm[\"description\"]\n",
    "            + \" : \"\n",
    "            + cur_theme[\"name\"]\n",
    "            + \" : \"\n",
    "            + cur_theme[\"description\"]\n",
    "        )\n",
    "\n",
    "        embedding = query_palm_embedding(cur_context)\n",
    "        \n",
    "        harm['context'] = cur_context\n",
    "        harm['embedding'] = embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = 50\n",
    "report_df_dict = {\n",
    "    'harm': [],\n",
    "    'report': []\n",
    "}\n",
    "\n",
    "for k in harm_taxonomy:\n",
    "    cur_theme = harm_taxonomy[k]\n",
    "    for harm in cur_theme[\"harms\"]:\n",
    "        if 'Non-consensual classifications' not in harm['description']:\n",
    "            continue\n",
    "        \n",
    "        cur_embedding = np.array(harm['embedding'])\n",
    "        report_df_dict['harm'].append(harm['name'] + ' : ' + harm['description'])\n",
    "\n",
    "        similarities = np.dot(doc_embeddings, cur_embedding)\n",
    "        top_indexes = np.argpartition(similarities, -top_k)[-top_k:]\n",
    "        \n",
    "        top_report_numbers = np.array(embeddings['reportNumbers'])[top_indexes]\n",
    "        top_similarities = similarities[top_indexes]\n",
    "\n",
    "        related_reports = []\n",
    "        for i, report_number in enumerate(top_report_numbers):\n",
    "            report = accident_reports[str(report_number)]\n",
    "            related_reports.append([report_number, report['title'], report['date'], top_similarities[i]])\n",
    "        \n",
    "        related_reports.sort(key=lambda x: x[3], reverse=True)\n",
    "        \n",
    "        report_string = ''\n",
    "        for r in related_reports:\n",
    "            report_string += str(r) + '\\n'\n",
    "            \n",
    "        report_df_dict['report'].append(report_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(report_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# related_reports = []\n",
    "\n",
    "# for k in accident_reports:\n",
    "#     report = accident_reports[k]\n",
    "            \n",
    "#     if 'environment' in report['text'].lower():\n",
    "#         related_reports.append([k, report['title'], report['date']])\n",
    "        \n",
    "#     report_string = ''\n",
    "#     for r in related_reports:\n",
    "#         report_string += str(r) + '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_df = pd.read_csv('./harm-report-tagging.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stereotyping\n",
      "Demeaning and alienating social groups\n",
      "Denying people opportunity to self-identify\n",
      "Opportunity loss\n",
      "Economic loss\n",
      "Alienation\n",
      "Increased labor\n",
      "Service or benefit loss\n",
      "Loss of agency or social control\n",
      "Technology-facilitated violence\n",
      "Diminished health and well-being\n",
      "Privacy violations\n",
      "Information harms\n",
      "Cultural harms\n",
      "Political and civic harms\n",
      "Macro socio-economic harms\n",
      "Environmental harms\n"
     ]
    }
   ],
   "source": [
    "def write_selected_reports(harm, report_nums):        \n",
    "    for k in harm_taxonomy:\n",
    "        cur_theme = harm_taxonomy[k]\n",
    "        for h in cur_theme[\"harms\"]:\n",
    "            if h['name'] == harm:\n",
    "                h['reportNumbers'] = list(map(int, report_nums))\n",
    "                return\n",
    "\n",
    "for i, row in tagged_df.iterrows():\n",
    "    harm_string = row['Harm'].split(' : ')\n",
    "    harm = harm_string[0]\n",
    "    print(harm)\n",
    "    description = harm_string[1]\n",
    "\n",
    "    report = row['Report']\n",
    "    selected = row['Selected'].split('\\n')\n",
    "    selected_report_nums = [int(re.sub(r\"\\['?(\\d+)'?,.*\", r'\\1', s)) for s in selected]\n",
    "    \n",
    "    write_selected_reports(harm, selected_report_nums)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "harm_taxonomy_no_emb = deepcopy(harm_taxonomy)\n",
    "\n",
    "for k in harm_taxonomy_no_emb:\n",
    "    cur_theme = harm_taxonomy_no_emb[k]\n",
    "    for harm in cur_theme[\"harms\"]:\n",
    "        if 'embedding' in harm:\n",
    "            harm.pop('embedding')\n",
    "            \n",
    "        if 'context' in harm:\n",
    "            harm.pop('context')\n",
    "            \n",
    "harm_data = {\n",
    "    'harmTaxonomy': harm_taxonomy_no_emb,\n",
    "    'failureModes': failure_modes\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Demeaning and alienating social groups',\n",
       " 'description': 'Narratives used to socially control or oppress social groups',\n",
       " 'failureModes': ['unsafe', 'toxic', 'opinionated'],\n",
       " 'reportNumbers': [2309, 2651, 2212, 2297, 2653, 1019, 48]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "harm_taxonomy_no_emb['Representational harms']['harms'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(harm_taxonomy, open('./harm-taxonomy-emb.json', 'w'))\n",
    "\n",
    "dump(harm_data, open('../src/components/harm-summary/harm-taxonomy.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prompt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
