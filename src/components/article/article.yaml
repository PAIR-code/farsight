intro:
  - >
    Prompt-based interfaces (e.g., <a
    href='https://aistudio.google.com/app/prompts/new_chat' target='_blank'
    rel='noreferrer'>Google AI Studio</a>, <a
    href='https://platform.openai.com/playground' target='_blank'
    rel='noreferrer'>OpenAI Playground</a>, and <a
    href='https://poloclub.github.io/wordflow/' target='_blank'
    rel='noreferrer'>Wordflow</a>)  for Large Language Models (LLMs) have made
    prototyping and building AI-powered applications easier than ever before.
    However, identifying potential harms that may arise from AI applications
    remains a challenge, particularly during prompt-based prototyping. To
    address this challenge, we designed and developed Farsight, a novel
    interactive <em>in situ</em> tool that helps people <strong>identify potential harms</strong>
    from the AI applications they are prototyping.

  - >
    Farsight is designed and developed for both AI prototypers (i.e., prompt
    creators) and developers of web-based prompting interfaces. First, AI
    prototypers can use Farsight in various ways: through this demo website, a
    <a href='https://github.com/PAIR-code/farsight' target='_blank'
    rel='noreferrer'>Chrome Extension</a> enabling it on Google AI Studio, or
    using a <a href='https://pypi.org/project/farsight/' target='_blank'
    rel='noreferrer'>Python package</a> to enable it on computational notebooks.
    Developers of prompting tools can easily integrate our open-source and
    reusable components into their AI prototyping tools.

usageIntro:
  - >
    Farsight includes a collection of <strong><em>in situ</em> widgets</strong>
    that can be integrated into diverse prompting workflows, such as web-based
    prompting GUIs and computational notebooks. To ensure users remain focused
    on their primary task or of writing prompting, Farsight uses progressive
    disclosure to gradually reveal these widgets with increasing complexity and
    engagement: (1) Alert Symbol → (2) Awareness Sidebar → (3) Harm
    Envisioner.

usageAlert:
  - >
    The Alert Symbol is an always-on display on top of the AI prototyping tool,
    displaying the alert level of a user's prompt. Every time the user runs
    their prompt, the Alert Symbol updates the alert level using the new prompt.
    Based on the computed alert level, there are three modes, each characterized
    by a progressively more attention-grabbing style. Thus, Farsight only
    disrupts AI prototypers' flow when their prompts require more caution.

  - >
    To categorize the potential harms that might arise from users' prompts,
    Farsight employs a novel technique that uses the <strong>similarity between
    the prompt and previously documented AI incident reports</strong> as a proxy
    for the prompt's alert level. First, we use LLM to extract high-dimensional
    latent representations (embeddings) of all AI incident reports indexed in
    the <a href='https://incidentdatabase.ai/' target='_blank'
    rel='noreferrer'>AI Incident Database</a>, which includes more than 3k
    community-curated news reports about AI failures and harms. Then, we extract
    the embedding of the user's prompt and compute pairwise cosine distances
    between the prompt embedding and AI incident report embeddings. We label
    each incident report as <code class="code">irrelevant</code>, <code
    class="code">remotely relevant</code>, and <code class="code">moderately
    relevant</code> based on two distance thresholds 0.69 and 0.75. We determine
    these two thresholds from an experiment with 1k random prompts.

  - >
    Finally, we show the numbers of AI incidents that are classified as <code
    class="code">remotely relevant</code> in an orange circle and <code
    class="code">moderately relevant</code> in a red circle as a proxy of the
    prompt's potential risk. In other words, we consider a prompt to have a
    higher risk <strong>if many AI incident reports are semantically and
    syntactically similar to it.</strong> See Figure 1 for a visualization of
    the embeddings of AI incident reports and prompts written by real users. An
    interactive version is available at <a
    href='https://poloclub.github.io/wizmap/?dataURL=https://huggingface.co/datasets/xiaohk/embeddings/resolve/main/ai-incident/data.ndjson&gridURL=https://huggingface.co/datasets/xiaohk/embeddings/resolve/main/ai-incident/grid.json'
    target='_blank' rel='noreferrer'>WizMap</a>.

usageIncident:
  - >
    After a user clicks the Alert Symbol, the Awareness Sidebar expands from the
    right of the AI prototyping tool, highlighting the potential consequences of
    AI applications or features that are based on the user's current prompt.

  - >
    To encourage users to consider potential risks associated with their
    prompts, the Incident Panel highlights news headlines of AI incidents that
    are relevant to the user's prompt. These incidents comprise the top 30
    incident reports that are classified as <code>moderately relevant</code> or
    <code>remotely relevant</code>, sorted in reverse order based on their
    embedding cosine distances to the embedding of the user's prompt. The
    thumbnails are color-coded based on the incident's relevancy level. Users
    can click the headline or the thumbnail to open the original incident report
    in a new tab. These real AI incidents can function as cautionary tales
    reminding users of potential AI harms.

usageUseCase:
  - >
    To help users imagine how their AI prototype may be used in AI applications
    or features, the Use Case Panel presents a diverse set of potential use
    cases that are generated by an LLM. Each use case is shown as a sentence
    describing how a particular group of end-users could use this AI application
    in a specific context. For example, for a writing tutor prompt, a potential
    use case can be “teachers use it to provide feedback on student writing.” We
    also use an LLM to generate a potential harm that could occur within that
    use case, shown below the use case sentence. For example, a harm for the
    teacher feedback use case can be “students may feel like they are not
    getting personalized feedback from their teachers.” We use few-shot learning
    to prompt the LLM to generate use cases and harms, whereas we generate use
    cases, stakeholders, and harms in Harm Envisioner.

  - >
    To help users assess and organize use cases and harms, we also leverage an
    LLM to categorize each use case as <span class="label
    label-intended">intended</span>, <span class="label
    label-high-stakes">high-stakes</span>, or <span class="label
    label-misuse">misuse</span>, although we acknowledge that these may vary by
    use cases, development and deployment contexts, as well as relevant policies
    or regulatory frameworks in various jurisdictions. These three categories
    are introduced by <a
    href='https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RE4ZzOI'
    target='_blank' rel='noreferrer'>responsible AI researchers</a> to help ML
    developers structure their harm envisioning process. The <span class="label
    label-intended">intended</span> use cases align with the
    development target use cases. The <span class="label
    label-high-stakes">high-stakes</span> use cases encompass those that may
    arise in high-stakes domains, such as medicine, finance, and the law. The
    <span class="label label-misuse">misuse</span> category includes scenarios
    where malicious actors exploit the AI application to cause harms. The Use
    Case Panel organizes use cases and harms into three tabs based on their
    categories. The first tab, "mix", provides an overview by showing one use
    case and its corresponding harm from each of the other tabs.

usageHarmEnvisioner:
  - >
    Both the Alert Symbol and the Awareness Sidebar provide easy-to-understand
    in-context reminders to help users reflect on potential harms associated
    with their prompts. However, instead of passively reading AI incident
    reports and LLM-generated content, some users desire to actively edit and
    add new <span class="colored use-case">use cases</span>, <span class="colored
    stakeholder">stakeholders</span>, and <span class="colored
    harm">harms</span>. Also, active participation—a key factor in
    learning—may help foster AI prototypers' ability to independently identify
    harms. Therefore, we design Harm Envisioner to support users in actively
    envisioning potential harms associated with their prompts.

  - >
    After clicking the "Envision Consequences & Harms" button in the Awareness
    Sidebar, Harm Envisioner appears as a pop-up window on top of the
    prompt-crafting tool. It begins with a text box filled with an LLM-generated
    <span class="colored summary">summary</span> of a user's prompt. The user is
    prompted to revise the <span class="colored summary">summary</span> to align with
    the target task in their prompt. Next, the window transitions into an
    interactive node-link tree visualization, where the user can pan and zoom to
    navigate the view. First, the window shows the user's <span class="colored
    summary">prompt summary</span> as the root of the tree which is visualized
    as a text box. The user can click the root node to ask AI to generate
    potential use cases of an AI application based on the user's prompt, and the
    use cases are visualized as the root's children nodes. Similarly, users can
    click a generated node to let AI generate its children nodes (stakeholders
    and then harms). There is a max of four layers, following an order of the
    user's <span class="colored summary">prompt summary</span> → <span
    class="colored use-case">use cases</span> → <span class="colored
    stakeholder">stakeholders</span> → <span class="colored harm">harms</span>.
    This layer order reflects the recommended harm envisioning workflow in
    responsible AI literature and helps users comprehend and organize diverse
    harms across different contexts.

whereTo:
  - >
    We develop Farsight for both AI prototypers (i.e., prompt creators) and
    prompting tool developers.

  - >
    AI prototypers can use Farsight in various ways: through this demo website,
    <a href='https://github.com/PAIR-code/farsight' target='_blank'
    rel='noreferrer'>a Chrome Extension</a>, and <a
    href='https://pypi.org/project/farsight/' target='_blank' rel='noreferrer'>a
    Python package</a>. The Chrome extension injects Farsight into Google AI Studio. The Python package allows AI
    prototypers to use Farsight in computational notebooks including Jupyter
    Notebook, JupyterLab, VS Code Notebook, and Google Colab. Visit <a
    href='https://colab.research.google.com/drive/1aTIW3tRX1BRcNMCg8bRKktpZxRXtMF3-?usp=sharing'
    target='_blank' rel='noreferrer'>this Colab Notebook</a> for a notebook demo.

  - >
    Developers of prompting tools can easily integrate Farsight into their
    web-based prompting GUIs. Farsight includes four open-source reusable Web
    Components: (1) Alert Symbol, (2) Incident Panel, (3) Use Case Panel, and
    (4) Harm Envisioner. Developers can import these components into their
    project regardless of the development stack (e.g., React, Svelte, Vue, or
    Vanilla JavaScript). Farsight uses LLM API endpoints to generate embeddings
    and content. The default is Gemini Pro. Developers can change it to other
    services like <a
    href='https://help.openai.com/en/articles/7102672-how-can-i-access-gpt-4'
    target='_blank' rel='noreferrer'>GPT 4</a> and <a
    href='https://docs.anthropic.com/claude/reference/getting-started-with-the-api'
    target='_blank' rel='noreferrer'>Claude 2</a>.

development:
  - >
    To make Farsight easily adoptable by both AI prototypers and AI companies,
    we implement Farsight to be <strong>model-agnostic</strong> and
    <strong>environment-agnostic</strong> and open-source our implementation. To
    help AI companies and researchers integrate Farsight into their AI
    prototyping tools, we leverage <a
    href='https://developer.mozilla.org/en-US/docs/Web/API/Web_components'
    target='_blank' rel='noreferrer'>Web Components</a> and <a
    href='https://lit.dev/' target='_blank' rel='noreferrer'>Lit</a> to
    implement Farsight as reusable modules, which can be easily integrated into
    any web-based interfaces regardless of their development stacks (e.g.,
    React, Vue, Svelte). We implement the interactive tree visualization using
    <a href='https://d3js.org/' target='_blank' rel='noreferrer'>D3.js</a> and
    embedding similarity computation using <a
    href='https://www.tensorflow.org/js' target='_blank'
    rel='noreferrer'>TensorFlow.js</a> with <a
    href='https://developer.mozilla.org/en-US/docs/Web/API/WebGL_API'
    target='_blank' rel='noreferrer'>WebGL acceleration</a>. We use <a
    href='https://github.com/poloclub/nova' target='_blank'
    rel='noreferrer'>NOVA</a> for the computational notebook integration.

who:
  - >
    Led by <a href='https://zijie.wang' target='_blank' rel='noreferrer'>Jay
    Wang</a>, Farsight started as an intern project at Google Research (PAIR and
    TASC). Farsight is created by <a href='https://zijie.wang' target='_blank'
    rel='noreferrer'>Jay Wang</a>, <a
    href='https://www.linkedin.com/in/chinmayk' target='_blank'
    rel='noreferrer'>Chinmay Kulkarni</a>, <a
    href='https://www.linkedin.com/in/laurenwilcox' target='_blank'
    rel='noreferrer'>Lauren Wilcox</a>, <a
    href='https://research.google/people/michael-terry/' target='_blank'
    rel='noreferrer'>Michael Terry</a>, and <a href='http://michaelmadaio.com/'
    target='_blank' rel='noreferrer'>Michael Madaio</a>.

  - >
    We express our gratitude to all anonymous participants who took part in our
    co-design and evaluation studies. A special thank you to Jaemarie Solyst and
    Savvas Petridis for piloting our studies. We are deeply thankful to our
    three anonymous raters for rating the harms collected during the evaluation
    study. We are immensely grate- ful for the invaluable feedback provided by
    Parker Barnes, Carrie Cai, Alex Fiannaca, Tesh Goyal, Ellen Jiang, Minsuk
    Kahng, Shaun Kane, Donald Martin, Alicia Parrish, Adam Pearce, Savvas
    Petridis, Mahima Pushkarna, Dheeraj Rajagopal, Kevin Robinson, Taylor Roper,
    Negar Rostamzadeh, Renee Shelby, Jaemarie Solyst, Vivian Tsai, James Wexler,
    Ann Yuan, and Andrew Zaldivar. Our gratitude also extends to the anonymous
    Google employees who generously allowed us to use their prompts to design
    and prototype Farsight. Furthermore, we are grateful to James Wexler, Paul
    Yang, Tulsee Doshi, and Marian Croak for their assistance in open-sourcing
    Farsight. Lastly, we would like to acknowledge the anonymous reviewers for
    their detailed and helpful feedback.

contribution:
  - >
    If you have any questions or feedback, feel free to <a
    href='https://github.com/PAIR-code/farsight/issues' target='_blank'
    rel='noreferrer'>open an issue</a> or contact <a href='https://zijie.wang'
    target='_blank' rel='noreferrer'>Jay Wang</a>. If you plan to integrate
    Farsight into your prompting tool, we are happy to help!

  - >
    We'd love to hear your experience with Farsight! If you'd like to share
    (e.g., what is your typical workflow to write prompts, what features of
    Farsight that you find helpful or unhelpful), please reach out to us.
    Farsight is an open-source project, and we welcome <a
    href='https://github.com/PAIR-code/farsight/pulls' target='_blank'
    rel='noreferrer'>pull requests</a> for new feature implementations and bug
    fixes, etc.

learnMore:
  - >
    To learn more about Farsight, please read our <a
    href='https://github.com/PAIR-code/farsight' target='_blank'
    rel='noreferrer'>research paper</a> (published at <a
    href='https://chi2024.acm.org/' target='_blank'
    rel='noreferrer'>CHI'24</a>). If you find Farsight useful for your research,
    please consider citing our paper. Thanks!

paper:
  bibtext: >
    @inproceedings{wangFarsightFosteringResponsible2024,
      title = {Farsight: {{Fostering Responsible AI Awareness During AI Application Prototyping}}},
      booktitle = {{{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
      author = {Wang, Zijie J. and Kulkarni, Chinmay and Wilcox, Lauren and Terry, Michael and Madaio, Michael},
      year = {2024}
    }

  title: >
    Farsight: Fostering Responsible AI Awareness During AI Application Prototyping

  paperLink: >
    https://github.com/PAIR-code/farsight

  venue: >
    CHI Conference on Human Factors in Computing Systems (CHI) 2024

  venueLink: >
    https://chi2024.acm.org/

  authors:
    - name: Zijie J. Wang
      url: 'https://zijie.wang'

    - name: Chinmay Kulkarni
      url: 'https://www.linkedin.com/in/chinmayk'

    - name: Lauren Wilcox
      url: 'https://www.linkedin.com/in/laurenwilcox'

    - name: Michael Terry
      url: 'https://research.google/people/michael-terry/'

    - name: Michael Madaio
      url: 'http://michaelmadaio.com/'

figures:
  alert:
    url: https://github.com/xiaohk/xiaohk/assets/15007159/8f15498c-8e2a-44d8-b569-73df5b16dabe
    caption: >
      A visualization of the PaLM 2 embeddings of 3,474 <a
      href='https://incidentdatabase.ai/' target='_blank' rel='noreferrer'>AI
      incident reports</a> (blue dots and contour) and 153 <a
      href='https://github.com/f/awesome-chatgpt-prompts' target='_blank'
      rel='noreferrer'>Awesome ChatGPT Prompts</a> (red dots and contour). The
      embeddings' dimensions were reduced from 768 to 2 using <a
      href='https://umap-learn.readthedocs.io/en/latest/' target='_blank'
      rel='noreferrer'>UMAP</a>. The rectangles and labels show the summaries of
      AI incident reports in high-density embedding neighborhoods.  The overlap
      between the red and blue contours indicates that user prompts can be in
      close proximity to AI incident reports in the 2D embedding space. This
      observation inspires us to use high-dimensional embedding similarities to
      calculate the alert levels in Farsight. Note that in this example, the 153
      user prompts form a cluster due to the primary focus of AwesomeGPT prompts
      on conversational agents. The distribution of our 1,000 internal prompts
      (featuring classification, translation, code generation, etc.) is more
      spread out. For an interactive version of this visualization, visit <a
      href='https://poloclub.github.io/wizmap/?dataURL=https://huggingface.co/datasets/xiaohk/embeddings/resolve/main/ai-incident/data.ndjson&gridURL=https://huggingface.co/datasets/xiaohk/embeddings/resolve/main/ai-incident/grid.json'
      target='_blank' rel='noreferrer'>WizMap</a>.

videos:
  alert:
    url: https://github.com/xiaohk/xiaohk/assets/15007159/49d9a0ce-fad3-46be-9c95-e1fceddecbb9
    caption: >
      The Alert Symbol is a persistent overlay that appears on top or next to
      the prompting tool. When a user runs the prompt, Farsight calculates the
      cosine distance between the prompt's embedding and the embeddings of AI
      incident reports. It then categorizes all incident reports as
      <em>moderately relevant</em>, <em>remotely relevant</em>, or
      <em>irrelevant</em> based on these distances. The Alert Symbol uses the
      number of <em>moderately relevant</em> and <em>remotely relevant</em>
      reports to determine an alert level (such as neutral, caution, or warning)
      and adjusts its display style to alert users accordingly.

  incident:
    url: https://github.com/xiaohk/xiaohk/assets/15007159/41e5a87a-0161-4b3a-aacd-f11a0cd2fb91
    caption: >
      The Incident Panel surfaces AI incident reports that are relevant to the
      user’s current prompt by using the cosine distance between the prompt’s
      embedding and the embeddings of AI incident reports. It displays the title
      and thumbnail of relevant reports in a list, highlighting moderately
      relevant reports with a red tint and remotely relevant reports with an
      orange tint. Users can click on a report to read the full article in a new
      browser tab.

  useCase:
    url: https://github.com/xiaohk/xiaohk/assets/15007159/7f8f4714-3fee-49d6-bc19-22a54c1c1bdd
    caption: >
      The Use Case Panel helps the user envision how different people may use
      the AI application that the user is prototyping. This panel uses LLM to
      generate potential use cases, stakeholders in each use case, and the
      potential harm that could occur to the stakeholders.  This panel also uses
      LLM to classify each use case as (1) <em>intended</em>, (2)
      <em>high-stakes</em>, and (3) <em>misuse</em>. The firs tab "Mix" shows
      one use case from each category. The <em>intended</em> use cases are those
      that align with the development target use cases. The <em>high-stakes</em>
      use cases encompass those that may arise in high-stakes domains, such as
      medicine, finance, and the law. The <em>misuse</em> category includes
      scenarios where malicious actors exploit the AI application to cause
      harms.

  harmEnvisioner:
    url: https://github.com/xiaohk/xiaohk/assets/15007159/11eb5fcb-8613-4074-b84f-9ea54a45be00
    caption: >
      The Harm Envisioner allows users to interactively envision potential harms
      using LLM. Initially, a summary of the user's prompt is generated for
      editing and confirmation. Then, LLM generates various use cases (intended,
      high-stakes, and misuse) which are organized in an interactive node-link
      visualization. Users can edit the content and click the Farsight button to
      have LLM envision potential stakeholders and harms related to the use
      case. Nodes can be edited, and deleted, and stakeholders (direct and
      indirect) and harms can be relabeled based on a <a
      href='https://arxiv.org/abs/2210.05791' target='_blank'
      rel='noreferrer'>harm taxonomy</a>). Additionally, users can rate the
      severity of a harm by clicking the fire icon.

  chromeExtension:
    url: https://github.com/xiaohk/xiaohk/assets/15007159/c72ce94e-0ba4-4535-ba84-b56e9f930b1c
    caption: >
      AI prototypers can use our Chrome extension to enable Farsight on Google AI Studio.

  notebook:
    url: https://github.com/xiaohk/xiaohk/assets/15007159/62b9a9c6-18b0-4953-b535-371ed9ccd9f8
    caption: >
      AI prototypers can use our Python package to use Farsight in computational
      notebooks, including Jupyter Notebook, JupyterLab, Google Colab, and VS
      Code Notebook. For JupyterLab users, we also recommend using <a
      href='https://github.com/xiaohk/stickyland' target='_blank'
      rel='noreferrer'>StickyLand</a> to create a persistent 2D dashboard with
      Farsight components.

youtubeTimes:
  - startTime: 0
    name: Introduction
    timestamp: (0:00-0:26)
  - startTime: 26
    name: Alert Symbol
    timestamp: (0:26-0:38)
  - startTime: 38
    name: Incident Panel
    timestamp: (0:38-0:53)
  - startTime: 63
    name: Use Case Panel
    timestamp: (0:53-1:12)
  - startTime: 72
    name: Legal Brief Writer Example
    timestamp: (1:12-1:45)
  - startTime: 105
    name: Translator Example
    timestamp: (1:45-1:55)
  - startTime: 115
    name: Harm Envisioner Summary
    timestamp: (1:55-2:05)
  - startTime: 125
    name: Use Cases
    timestamp: (2:05-2:20)
  - startTime: 140
    name: Stakeholders & Harms
    timestamp: (2:20-2:35)
  - startTime: 135
    name: Human-AI Collaborative Envisioning
    timestamp: (2:35-3:50)
  - startTime: 230
    name: Export Harms
    timestamp: (3:50-4:00)
  - startTime: 240
    name: Google AI Studio
    timestamp: (4:00-4:20)
  - startTime: 260
    name: Computational notebook
    timestamp: (4:20-4:50)
  - startTime: 290
    timestamp: (4:50-5:00)
    name: Live Demo
